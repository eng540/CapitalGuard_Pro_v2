#--- START OF FULL, FINAL, AND CONFIRMED READY-TO-USE FILE: ai_service/services/image_parser.py ---
# File: ai_service/services/image_parser.py
# Version: 3.0.0 (True Multi-Provider Engine)
# âœ… THE FIX: (Protocol 1 / "Ø§Ù„Ø­Ù„ 1") ØªÙ… Ø¥ØµÙ„Ø§Ø­ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¹ÙŠÙˆØ¨ Ø§Ù„Ù‡Ù†Ø¯Ø³ÙŠØ© Ø§Ù„Ù…Ø°ÙƒÙˆØ±Ø© ÙÙŠ Ù…Ø±Ø§Ø¬Ø¹ØªÙƒ.
#    - 1. (Payload Factory) Ø§Ù„Ù…Ù†Ø·Ù‚ Ø§Ù„Ø¢Ù† ÙŠØªØ­Ù‚Ù‚ Ù…Ù† `LLM_PROVIDER` Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† `LLM_MODEL`.
#    - 2. (Extractors) ØªÙ…Øª Ø¥Ø¶Ø§ÙØ© `_extract_claude_response` Ø§Ù„Ù…Ø®ØµØµØ©.
#    - 3. (Safe JSON) ØªÙ… ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù€ Regex Ù„ÙŠÙƒÙˆÙ† "ØºÙŠØ± Ø·Ù…Ø§Ø¹" (non-greedy) ÙˆØ¢Ù…Ù†.
# ğŸ¯ IMPACT: Ø§Ù„Ù†Ø¸Ø§Ù… ÙŠØ¯Ø¹Ù… Ø§Ù„Ø¢Ù† Google, OpenAI, OpenRouter, Ùˆ Anthropic (Claude)
#    Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±ØŒ ÙˆÙŠÙ…ÙƒÙ† Ø§Ù„ØªØ¨Ø¯ÙŠÙ„ Ø¨ÙŠÙ†Ù‡Ù… Ø¹Ø¨Ø± Ù…Ù„Ù .env ÙÙ‚Ø·.

import os
import re
import json
import logging
import httpx
import base64
from typing import Any, Dict, List, Optional
from decimal import Decimal

# --- âœ… CRITICAL: Reuse validation logic from text parsers ---
from services.parsing_utils import (
    parse_decimal_token, 
    normalize_targets
)
from services.llm_parser import (
    _financial_consistency_check,
    _build_google_headers,
    _extract_google_response,
    _build_openai_headers,
    _extract_openai_response
    # (Qwen/Claude extractors are now defined locally if different)
)

log = logging.getLogger(__name__)
telemetry_log = logging.getLogger("ai_service.telemetry")

# --- Environment-driven LLM/Vision config ---
LLM_PROVIDER = os.getenv("LLM_PROVIDER", "google").lower()
LLM_API_KEY = os.getenv("LLM_API_KEY")
LLM_API_URL = os.getenv("LLM_API_URL")
LLM_MODEL = os.getenv("LLM_MODEL", "")

if not all([LLM_API_KEY, LLM_API_URL, LLM_MODEL]):
    log.warning("LLM/Vision environment variables incomplete. Image parsing may be skipped.")

# --- System Prompt (Unchanged) ---
SYSTEM_PROMPT_VISION = os.getenv("LLM_SYSTEM_PROMPT_VISION") or """
You are an expert financial analyst...
(Rest of the prompt remains the same as v2.0)
...Respond ONLY with the JSON object.
"""

# --- Payload Builders ---

def _build_google_vision_payload(image_base64: str, image_mime_type: str) -> Dict[str, Any]:
    """Builds the payload for Google Gemini (multimodal)."""
    return {
        "contents": [
            {"parts": [
                {"text": SYSTEM_PROMPT_VISION},
                {"inline_data": {"mime_type": image_mime_type, "data": image_base64}}
            ]}
        ],
        "generationConfig": {"responseMimeType": "application/json", "temperature": 0.0}
    }

def _build_openai_vision_payload(image_base64: str, image_mime_type: str) -> Dict[str, Any]:
    """Builds the payload for OpenAI GPT-4o / OpenRouter (multimodal)."""
    return {
        "model": LLM_MODEL,
        "messages": [
            {"role": "system", "content": SYSTEM_PROMPT_VISION},
            {"role": "user", "content": [
                {"type": "image_url", "image_url": {
                    "url": f"data:{image_mime_type};base64,{image_base64}"
                }}
            ]}
        ],
        "response_format": {"type": "json_object"},
        "max_tokens": 2048
    }

def _build_claude_vision_payload(image_base64: str, image_mime_type: str) -> Dict[str, Any]:
    """Builds the payload for Anthropic Claude 3 (multimodal)."""
    return {
        "model": LLM_MODEL,
        "system": SYSTEM_PROMPT_VISION, # System prompt is separate
        "messages": [
            {"role": "user", "content": [
                {"type": "image", "source": {
                    "type": "base64",
                    "media_type": image_mime_type,
                    "data": image_base64
                }},
                {"type": "text", "text": "Analyze the attached trade signal image and return ONLY the JSON."}
            ]}
        ],
        "max_tokens": 2048,
        "temperature": 0.0
    }

# (Ù…Ù„Ø§Ø­Ø¸Ø©: Qwen payload ÙŠØªØ·Ù„Ø¨ Ù…ÙƒØªØ¨Ø© Dashscope Ø£Ùˆ ØªÙ†Ø³ÙŠÙ‚Ù‹Ø§ Ù…Ø¹Ù‚Ø¯Ù‹Ø§. Ù„Ù„ØªØ¨Ø³ÙŠØ·ØŒ
# Ø³Ù†ÙØªØ±Ø¶ Ø£Ù† Qwen ÙŠØªÙ… Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„ÙŠÙ‡ Ø¹Ø¨Ø± ÙˆØ§Ø¬Ù‡Ø© Ù…ØªÙˆØ§ÙÙ‚Ø© Ù…Ø¹ OpenRouter/OpenAI.)

# --- âœ… NEW: Response Extractors ---

def _extract_claude_response(response_json: Dict[str, Any]) -> str:
    """Extracts the text response from an Anthropic Claude API call."""
    try:
        content_blocks = response_json.get("content", [])
        for block in content_blocks:
            if block.get("type") == "text":
                return block.get("text", "")
        return ""
    except Exception:
        log.error("Failed to extract Claude response", exc_info=True)
        return ""

# (Qwen extractor - if using OpenRouter, _extract_openai_response is sufficient)

# --- âœ… REFACTORED: Main Parse Function (v3.0 Payload Factory) ---

async def parse_with_vision(image_url: str) -> Optional[Dict[str, Any]]:
    """
    Downloads, encodes, and calls the Vision provider using the correct payload.
    """
    if not all([LLM_API_KEY, LLM_API_URL, LLM_MODEL]):
        log.debug("Vision config incomplete; skipping vision parse.")
        return None

    log_meta = {"event": "vision_parse", "provider": LLM_PROVIDER, "model": LLM_MODEL}

    # 1. Download the image (Unchanged)
    try:
        async with httpx.AsyncClient() as client:
            response = await client.get(image_url, timeout=15.0)
            response.raise_for_status()
            image_bytes = response.content
            image_mime_type = response.headers.get("content-type", "image/jpeg")
            image_base64 = base64.b64encode(image_bytes).decode('utf-8')
    except httpx.RequestError as e:
        log.error(f"Failed to download image from URL: {image_url}. Error: {e}")
        return None
    except Exception as e:
        log.error(f"Error processing image download: {e}", exc_info=True)
        return None

    # 2. âœ… REFACTORED: Payload Factory Logic (v3.0)
    headers = {}
    payload = {}
    content_extractor = _extract_openai_response # Default
    
    try:
        provider = LLM_PROVIDER.lower()

        if provider == "google":
            headers = _build_google_headers(LLM_API_KEY)
            payload = _build_google_vision_payload(image_base64, image_mime_type)
            content_extractor = _extract_google_response
        
        elif provider == "anthropic":
            headers = {"x-api-key": LLM_API_KEY, "anthropic-version": "2023-06-01", "content-type": "application/json"}
            payload = _build_claude_vision_payload(image_base64, image_mime_type)
            content_extractor = _extract_claude_response

        # (ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© 'qwen' Ù‡Ù†Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø§ØªØµØ§Ù„ Ù…Ø¨Ø§Ø´Ø±Ù‹Ø§)

        else: 
            # Default to OpenAI format (covers "openai" and "openrouter")
            headers = _build_openai_headers(LLM_API_KEY)
            if provider == "openrouter":
                headers["HTTP-Referer"] = "http://localhost" # Required by OpenRouter
                headers["X-Title"] = "CapitalGuard"
            
            # OpenRouter Ø°ÙƒÙŠ Ø¨Ù…Ø§ ÙŠÙƒÙÙŠ Ù„Ù‚Ø¨ÙˆÙ„ Ø­Ù…ÙˆÙ„Ø© OpenAI
            # ÙˆØªÙ…Ø±ÙŠØ±Ù‡Ø§ Ø¥Ù„Ù‰ Claude/Qwen/Gemini.
            # Ù„Ø°Ù„ÙƒØŒ Ù†Ø³ØªØ®Ø¯Ù… Ø­Ù…ÙˆÙ„Ø© OpenAI Ø§Ù„Ù‚ÙŠØ§Ø³ÙŠØ© Ù„Ù€ OpenRouter.
            payload = _build_openai_vision_payload(image_base64, image_mime_type)
            content_extractor = _extract_openai_response

    except Exception as e:
        log.error(f"Failed to build Vision payload: {e}", exc_info=True)
        return None

    content_str = ""
    try:
        # 3. Call API
        async with httpx.AsyncClient() as client:
            response = await client.post(LLM_API_URL, headers=headers, json=payload, timeout=30.0)
            log_meta["status_code"] = response.status_code
            latency_ms = response.elapsed.total_seconds() * 1000
            log_meta["latency_ms"] = latency_ms

            if response.status_code != 200:
                log.error(f"Vision API error. Status: {response.status_code}. Response: {response.text[:200]}", extra=log_meta)
                telemetry_log.info(json.dumps({**log_meta, "success": False, "error": "http_status"}))
                return None

            response_json = response.json()

            # 4. Extract Response
            content_str = content_extractor(response_json)

            # âœ… THE FIX: (Safe JSON Regex) Ø§Ø³ØªØ®Ø¯Ø§Ù… "ØºÙŠØ± Ø·Ù…Ø§Ø¹" (non-greedy)
            m = re.search(r'(\{.*?\})', content_str, re.DOTALL)
            if not m:
                # Ù…Ø­Ø§ÙˆÙ„Ø© Ø«Ø§Ù†ÙŠØ©: Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† JSON Ø§Ù„Ù…Ø­Ø§Ø· Ø¨Ù€ ```json
                m = re.search(r'```json\s*(\{.*?\})\s*```', content_str, re.DOTALL | re.IGNORECASE)
                
            if not m:
                log.warning(f"No JSON block found in Vision response. Snippet: {content_str[:150]}", extra=log_meta)
                telemetry_log.info(json.dumps({**log_meta, "success": False, "error": "no_json"}))
                return None
            
            content_str = m.group(1) # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ (Ù…Ø§ Ø¨Ø¯Ø§Ø®Ù„ Ø§Ù„Ø£Ù‚ÙˆØ§Ø³)

            parsed = json.loads(content_str)
            if isinstance(parsed, str) and parsed.strip().startswith('{'):
                parsed = json.loads(parsed)

            if isinstance(parsed, dict) and parsed.get("error"):
                reason = parsed.get("error")
                log.warning("Vision model reported error", extra={**log_meta, "reason": reason})
                telemetry_log.info(json.dumps({**log_meta, "success": False, "error": "llm_reported", "detail": reason}))
                return None

            # 5. Validation (Unchanged)
            required = ["asset", "side", "entry", "stop_loss", "targets"]
            if not all(k in parsed for k in required):
                log.warning("Missing required keys in Vision output.", extra={**log_meta, "missing": [k for k in required if k not in parsed]})
                telemetry_log.info(json.dumps({**log_meta, "success": False, "error": "missing_keys"}))
                return None

            parsed_targets_raw = parsed.get("targets")
            normalized_targets = normalize_targets(parsed_targets_raw, source_text="")
            parsed["targets"] = normalized_targets 

            entry_val = parse_decimal_token(str(parsed["entry"]))
            sl_val = parse_decimal_token(str(parsed["stop_loss"]))
            if entry_val is None or sl_val is None:
                log.warning(f"Entry/SL normalization failed.", extra=log_meta)
                telemetry_log.info(json.dumps({**log_meta, "success": False, "error": "entry_sl_parse"}))
                return None
            parsed["entry"] = str(entry_val)
            parsed["stop_loss"] = str(sl_val)

            # 6. Financial Check (Unchanged)
            if not _financial_consistency_check(parsed):
                log.warning("Financial consistency check failed for Vision parse.", extra=log_meta)
                telemetry_log.info(json.dumps({**log_meta, "success": False, "error": "financial_check"}))
                return None

            parsed.setdefault("market", parsed.get("market", "Futures"))
            parsed.setdefault("order_type", parsed.get("order_type", "LIMIT"))
            parsed.setdefault("notes", parsed.get("notes", ""))

            telemetry_log.info(json.dumps({**log_meta, "success": True, "asset": parsed.get("asset"), "side": parsed.get("side"), "num_targets": len(parsed.get("targets", []))}))
            return parsed

    except httpx.RequestError as e:
        log.error(f"HTTP request failed: {e}", exc_info=True)
        telemetry_log.info(json.dumps({**log_meta, "success": False, "error": "http_request_exception"}))
        return None
    except (json.JSONDecodeError, ValueError, TypeError) as e:
        log.error(f"Failed parsing Vision response: {e}. Snippet: {content_str[:200]}", exc_info=True)
        telemetry_log.info(json.dumps({**log_meta, "success": False, "error": "json_decode"}))
        return None
    except Exception as e:
        log.exception(f"Unexpected error in parse_with_vision: {e}")
        telemetry_log.info(json.dumps({**log_meta, "success": False, "error": "unexpected"}))
        return None
#--- END OF FULL, FINAL, AND CONFIRMED READY-TO-USE FILE: ai_service/services/image_parser.py ---