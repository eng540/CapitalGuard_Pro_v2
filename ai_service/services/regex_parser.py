#--- START OF FULL, FINAL, AND CONFIRMED READY-TO-USE FILE: ai_service/services/regex_parser.py ---
# File: ai_service/services/regex_parser.py
# Version: 1.5.0 (Decoupled)
# âœ… THE FIX: (Protocol 1) ØªÙ… ÙØµÙ„ Ø§Ù„Ø®Ø¯Ù…Ø© Ø¹Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.
#    - `parse_with_regex` Ù„Ù… ØªØ¹Ø¯ ØªØªÙ„Ù‚Ù‰ `session`. Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø°Ù„ÙƒØŒ ØªØªÙ„Ù‚Ù‰ `user_id` (Ø§Ø®ØªÙŠØ§Ø±ÙŠ).
#    - ØªÙ…Øª Ø¥Ø²Ø§Ù„Ø© Ù…Ù†Ø·Ù‚ Ø¬Ù„Ø¨ Ø§Ù„Ù‚ÙˆØ§Ù„Ø¨ Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (DB templates).
#    - ØªØ¹ØªÙ…Ø¯ Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ø¢Ù† *ÙÙ‚Ø·* Ø¹Ù„Ù‰ Ù…Ø­Ù„Ù„ Key-Value Ø§Ù„Ø¨Ø³ÙŠØ· ÙƒÙ€ "Ù…Ø³Ø§Ø± Ø³Ø±ÙŠØ¹".
# ğŸ¯ IMPACT: Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù Ù„Ù… ÙŠØ¹Ø¯ ÙŠØªØµÙ„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª. (Ù„ØªØ­Ø³ÙŠÙ† Ù‡Ø°Ø§ØŒ ÙŠØ¬Ø¨ Ù†Ù‚Ù„ Ù…Ù†Ø·Ù‚ Ù‚ÙˆØ§Ù„Ø¨ DB Ø¥Ù„Ù‰ `api`).

import re
import unicodedata
import logging
from typing import Dict, Any, Optional, List
from decimal import Decimal

# âŒ REMOVED DB IMPORTS
# from sqlalchemy.orm import Session
# from sqlalchemy import select
# from models import ParsingTemplate
# from database import session_scope

# --- âœ… Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ù…ØµØ¯Ø± Ø§Ù„Ø­Ù‚ÙŠÙ‚Ø© Ø§Ù„ÙˆØ­ÙŠØ¯ ---
from services.parsing_utils import (
    parse_decimal_token, 
    normalize_targets
)

log = logging.getLogger(__name__)

# --- Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© (Ù„Ù„ØªØ·Ø¨ÙŠØ¹ ÙˆØ§Ù„Ø¨Ø­Ø« ÙÙ‚Ø·) ---

_AR_TO_EN_DIGITS = str.maketrans("Ù Ù¡Ù¢Ù£Ù¤Ù¥Ù¦Ù§Ù¨Ù©", "0123456789")

def _normalize_text(text: str) -> str:
    if not text: return ""
    s = unicodedata.normalize("NFKC", text)
    s = s.translate(_AR_TO_EN_DIGITS)
    s = s.replace("ØŒ", ",")
    s = re.sub(r'[^\w\s\u0600-\u06FF@:.,\d\-+%$#/|â†’]', ' ', s, flags=re.UNICODE)
    s = re.sub(r'(\r\n|\r|\n){2,}', '\n', s)
    s = re.sub(r'\s{2,}', ' ', s)
    return s.strip()

def _normalize_for_key(text: str) -> str:
    return _normalize_text(text).upper()

def _find_side(text: str) -> Optional[str]:
    txt = text.upper()
    side_maps = {
        'LONG': ('LONG', 'BUY', 'Ø´Ø±Ø§Ø¡', 'ØµØ¹ÙˆØ¯'),
        'SHORT': ('SHORT', 'SELL', 'Ø¨ÙŠØ¹', 'Ù‡Ø¨ÙˆØ·'),
    }
    for s, keywords in side_maps.items():
        if any(re.search(r'\b' + re.escape(kw) + r'\b', txt) for kw in keywords):
            return s
    return None

def _parse_simple_key_value(text: str) -> Optional[Dict[str, Any]]:
    """
    A simple fallback parser that looks for common Arabic/English keys.
    """
    try:
        normalized_upper = _normalize_for_key(text)
        
        # âœ… HOTFIX (v1.4): ØªÙ… ØªÙˆØ³ÙŠØ¹ Regex Ø§Ù„Ø®Ø§Øµ Ø¨Ø§Ù„Ø£Ù‡Ø¯Ø§Ù Ù„ÙŠØ´Ù…Ù„ / - â†’
        keys = {
            'asset': r'#([A-Z0-9]{3,12})',
            'side': r'(LONG|BUY|Ø´Ø±Ø§Ø¡|ØµØ¹ÙˆØ¯|SHORT|SELL|Ø¨ÙŠØ¹|Ù‡Ø¨ÙˆØ·)',
            'entry': r'(ENTRY|Ø¯Ø®ÙˆÙ„|Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø¯Ø®ÙˆÙ„|BUY)[:\sâ†’]+([\d.,KMB]+)',
            'stop_loss': r'(SL|STOP|Ø§ÙŠÙ‚Ø§Ù Ø®Ø³Ø§Ø±Ø©|STOP LOSS)[:\sâ†’]+([\d.,KMB]+)',
            'targets': r'(TARGETS|TP|Ø§Ù„Ø§Ù‡Ø¯Ø§Ù|Ø§Ù‡Ø¯Ø§Ù|SELL TARGETS)[:\s\nâ†’]+((?:[\d.,KMB@%\s\n/\-â†’]+))'
        }

        parsed = {}

        side_match = re.search(keys['side'], normalized_upper)
        if side_match:
            parsed['side'] = _find_side(side_match.group(1))

        asset_match = re.search(keys['asset'], normalized_upper)
        if asset_match:
            asset_str = asset_match.group(1)
            if asset_str in ["BTC", "ETH", "SOL", "BNB", "XRP", "ADA", "DOT", "LINK", "MATIC", "AVAX", "TURTLE"]:
                parsed['asset'] = f"{asset_str}USDT"
            else:
                parsed['asset'] = asset_str
        
        entry_match = re.search(keys['entry'], normalized_upper)
        if entry_match:
            entry_val = parse_decimal_token(entry_match.group(2))
            parsed['entry'] = str(entry_val) if entry_val is not None else None

        sl_match = re.search(keys['stop_loss'], normalized_upper)
        if sl_match:
            sl_val = parse_decimal_token(sl_match.group(2))
            parsed['stop_loss'] = str(sl_val) if sl_val is not None else None

        targets_match = re.search(keys['targets'], normalized_upper, re.DOTALL)
        if targets_match:
            target_tokens_str = targets_match.group(2)
            parsed['targets'] = normalize_targets(target_tokens_str, source_text=text)
        
        required_keys = ['asset', 'side', 'entry', 'stop_loss', 'targets']
        if not all(parsed.get(k) for k in required_keys):
            log.debug(f"Simple KV parser found data, but missing required keys. Found: {parsed.keys()}")
            return None
        
        log.info(f"Simple KV parser successfully extracted data (Asset: {parsed['asset']})")
        parsed.setdefault("market", "Futures")
        parsed.setdefault("order_type", "LIMIT")
        parsed.setdefault("notes", None) 
        
        # âœ… REFACTORED: Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¹ Decimals
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ø¥Ù„Ù‰ Decimal Ù„ØªØªØ³Ù‚ Ù…Ø¹ Ù…Ø®Ø±Ø¬Ø§Øª llm_parser
        parsed['entry'] = parse_decimal_token(parsed['entry'])
        parsed['stop_loss'] = parse_decimal_token(parsed['stop_loss'])
        # targets is already list[dict] with Decimals from normalize_targets
        
        return parsed

    except Exception as e:
        log.warning(f"Error in _parse_simple_key_value: {e}", exc_info=False)
        return None


# --- Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„Ù…Ø­Ù„Ù„ ---
# âœ… REFACTORED: (Protocol 1)
def parse_with_regex(text: str, user_id: Optional[int]) -> Optional[Dict[str, Any]]:
    """
    ÙŠØ­Ø§ÙˆÙ„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‚ÙˆØ§Ù„Ø¨ RegexØŒ Ø«Ù… Key-Value Ø§Ù„Ø¨Ø³ÙŠØ·.
    (ØªÙ…Øª Ø¥Ø²Ø§Ù„Ø© Ù…Ù†Ø·Ù‚ Ù‚ÙˆØ§Ù„Ø¨ DB - ÙŠØ¹ØªÙ…Ø¯ Ø§Ù„Ø¢Ù† ÙÙ‚Ø· Ø¹Ù„Ù‰ Simple KV)
    """
    
    # âŒ REMOVED: Database query for templates
    
    # --- 1. Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ø³Ø±ÙŠØ¹ (Ù‚ÙˆØ§Ù„Ø¨ DB) ---
    # (ØªÙ…Øª Ø¥Ø²Ø§Ù„Ø© Ù‡Ø°Ø§ Ø§Ù„Ù‚Ø³Ù…. Ù„Ø¥Ø¹Ø§Ø¯Ø© ØªÙØ¹ÙŠÙ„Ù‡ØŒ ÙŠØ¬Ø¨ Ù†Ù‚Ù„ Ù‡Ø°Ø§ Ø§Ù„Ù…Ù†Ø·Ù‚ Ø¥Ù„Ù‰ `api`
    # ÙˆØªÙ…Ø±ÙŠØ± Ø§Ù„Ù‚ÙˆØ§Ù„Ø¨ Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¥Ù„Ù‰ `ai-service`)

    # --- 2. Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ (Ù…Ø­Ù„Ù„ Key-Value Ø§Ù„Ø¨Ø³ÙŠØ·) ---
    log.debug(f"User {user_id}: Trying simple Key-Value parser...")
    simple_result = _parse_simple_key_value(text)
    if simple_result:
        return simple_result

    log.debug("RegexParser: All regex paths failed.")
    return None
#--- END OF FULL, FINAL, AND CONFIRMED READY-TO-USE FILE: ai_service/services/regex_parser.py ---